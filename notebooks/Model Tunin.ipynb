{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "357c4c2f-43b3-437a-bb2c-fbdca5f9ab70",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load saved pipeline + transformed datasets"
    }
   },
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "load_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "pipeline = joblib.load(os.path.join(load_dir, \"stedi_feature_pipeline.pkl\"))\n",
    "X_train_transformed = joblib.load(os.path.join(load_dir, \"X_train_transformed.pkl\"))\n",
    "X_test_transformed  = joblib.load(os.path.join(load_dir, \"X_test_transformed.pkl\"))\n",
    "y_train = joblib.load(os.path.join(load_dir, \"y_train.pkl\"))\n",
    "y_test  = joblib.load(os.path.join(load_dir, \"y_test.pkl\"))\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test  = to_float_matrix(X_test_transformed)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c643ee-7cad-44e4-8478-db463683b7fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convert to float matrix + flatten labels + sanity-check shapes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test  = to_float_matrix(X_test_transformed)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2e6267-6371-44fd-8411-a26bb0c5f824",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Logistic Regression"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg_params = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "log_reg_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=300),\n",
    "    log_reg_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "\n",
    "log_reg_best_params = log_reg_grid.best_params_\n",
    "log_reg_best_score = log_reg_grid.best_score_\n",
    "\n",
    "log_reg_best_params, log_reg_best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d347bedb-97f4-48c1-acb4-dd39a759a325",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Random Forest tuning"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_params,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "rf_best_params = rf_grid.best_params_\n",
    "rf_best_score = rf_grid.best_score_\n",
    "\n",
    "rf_best_params, rf_best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c877629b-bdbf-4881-a614-ce48d2850e45",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Comparison"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression (tuned)\": log_reg_best_score,\n",
    "    \"Random Forest (tuned)\": rf_best_score\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c90b11c-aa2b-4400-b87a-f9b33db6b6e7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Choose best model"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the better model based on best_score_\n",
    "if rf_best_score > log_reg_best_score:\n",
    "    best_model = rf_grid.best_estimator_\n",
    "    best_model_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = log_reg_grid.best_estimator_\n",
    "    best_model_name = \"Logistic Regression\"\n",
    "\n",
    "best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c77dd85f-6a3f-49bd-bc34-ea5c08a97d54",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save"
    }
   },
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "save_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "joblib.dump(best_model, os.path.join(save_dir, \"stedi_best_model.pkl\"))\n",
    "print(\"Saved best model to:\", os.path.join(save_dir, \"stedi_best_model.pkl\"))\n",
    "print(\"Folder contains:\", os.listdir(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a37e1b-34a9-4eea-a04a-80ba581ad405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "# rows = true [no_step, step], cols = predicted [no_step, step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ab8ae8-c7bf-4d97-bcca-df329d556a94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Markdown\n",
    "Both tuned models performed the same. Logistic Regression reached a best 3-fold CV accuracy of 0.9511214840660257 with C=0.01, penalty=l2, solver=lbfgs, and Random Forest also reached 0.9511214840660257 with max_depth=5, n_estimators=50, min_samples_split=2, min_samples_leaf=1. On the test set, both achieved 0.9511166072597658 accuracy, so I selected Logistic Regression as the final model since it matches performance while being simpler to interpret and reuse later.\n",
    "\n",
    "That said, accuracy is misleading here because the classes are imbalanced. The model predicted “step” for every test row (confusion matrix [[0, 2016], [0, 39225]]), giving 0.00 recall for the no_step class. With more time, I would tune using a metric like balanced accuracy or macro F1 and test class_weight=\"balanced\" to improve minority-class detection. Hyperparameter tuning can unintentionally increase unfairness when it optimizes a metric that rewards majority-class performance; transparency matters because it forces honest reporting of what the model actually does, aligning with the gospel principle of truthful evaluation and steady improvement."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Model Tunin",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
