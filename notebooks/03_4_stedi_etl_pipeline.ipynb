{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f0577fb-3690-4b8f-94ab-61c60360761a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_4_stedi_etl_pipeline\n",
    "# Loads raw tables from bronze and keeps everything deterministic for job runs.\n",
    "\n",
    "from pyspark.sql.functions import col, regexp_extract, when, lit\n",
    "\n",
    "# Always set schemas explicitly so the job doesn't depend on whatever schema the cluster \"feels like\" today.\n",
    "spark.sql(\"USE bronze\")\n",
    "\n",
    "device_raw = spark.table(\"device_messages_raw\")\n",
    "steps_raw  = spark.table(\"rapid_step_tests_raw\")\n",
    "\n",
    "print(\"Loaded:\", device_raw.count(), \"device rows\")\n",
    "print(\"Loaded:\", steps_raw.count(), \"step-test rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e7a79bc-99e6-4d81-bd28-da068854e482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark.sql(\"USE bronze\")\n",
    "\n",
    "device_raw = spark.table(\"device_messages_raw\")\n",
    "steps_raw  = spark.table(\"rapid_step_tests_raw\")\n",
    "\n",
    "print(\"Loaded:\", device_raw.count(), \"device rows\")\n",
    "print(\"Loaded:\", steps_raw.count(), \"step-test rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca635a80-97d3-440e-8488-fe348a65d007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, when, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44c7590-a188-4c70-8a89-5cc772ed560d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean distance (e.g., \"75cm\" -> 75) and keep the columns needed for labeling/output.\n",
    "device_prepped = (\n",
    "    device_raw\n",
    "    .withColumn(\"distance_cm\", regexp_extract(col(\"distance\"), r\"(\\d+)\", 1).cast(\"int\"))\n",
    "    .select(\"timestamp\", \"device_id\", \"sensor_type\", \"distance_cm\")\n",
    ")\n",
    "\n",
    "# Keep only step-test windows (cast to long to match timestamp type).\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "# Normalize step-test window timestamps to millisecond epoch.\n",
    "# Heuristic: seconds epochs are ~1e9–1e10; milliseconds epochs are ~1e12–1e13.\n",
    "steps_window = (\n",
    "    steps_raw\n",
    "    .select(\n",
    "        \"device_id\",\n",
    "        col(\"start_time\").cast(\"long\").alias(\"start_raw\"),\n",
    "        col(\"stop_time\").cast(\"long\").alias(\"stop_raw\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"start_time_ms\",\n",
    "        when(col(\"start_raw\") < lit(10**11), col(\"start_raw\") * lit(1000)).otherwise(col(\"start_raw\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"stop_time_ms\",\n",
    "        when(col(\"stop_raw\") < lit(10**11), col(\"stop_raw\") * lit(1000)).otherwise(col(\"stop_raw\"))\n",
    "    )\n",
    "    .select(\n",
    "        \"device_id\",\n",
    "        col(\"start_time_ms\").alias(\"start_time\"),\n",
    "        col(\"stop_time_ms\").alias(\"stop_time\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "display(steps_window.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c446f7-1e70-44b1-a305-d698df910847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show what variables exist (quick sanity check)\n",
    "[x for x in dir() if x.endswith(\"_df\") or \"final\" in x or \"device\" in x or \"steps\" in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3910bd1-3780-4e5d-8711-8c851cd82d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "final_df = (\n",
    "    device_prepped.alias(\"d\")\n",
    "    .join(\n",
    "        steps_window.alias(\"s\"),\n",
    "        (col(\"d.device_id\") == col(\"s.device_id\")) &\n",
    "        (col(\"d.timestamp\").between(col(\"s.start_time\"), col(\"s.stop_time\"))),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"step_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), lit(\"step\")).otherwise(lit(\"no_step\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"source_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), lit(\"step\")).otherwise(lit(\"device\"))\n",
    "    )\n",
    "    .select(\n",
    "        col(\"d.timestamp\").alias(\"timestamp\"),\n",
    "        col(\"d.device_id\").alias(\"device_id\"),\n",
    "        col(\"d.sensor_type\").alias(\"sensor_type\"),\n",
    "        col(\"d.distance_cm\").alias(\"distance_cm\"),\n",
    "        \"step_label\",\n",
    "        \"source_label\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9414687c-6a30-40a7-bde0-3826917d5d99",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769564783637}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime, to_timestamp\n",
    "\n",
    "final_df_renamed = (\n",
    "    final_df\n",
    "    .withColumn(\"timestamp_ts\", to_timestamp(from_unixtime(col(\"timestamp\") / 1000)))\n",
    "    .select(\n",
    "        col(\"timestamp_ts\").alias(\"timestamp\"),\n",
    "        \"device_id\",\n",
    "        \"sensor_type\",\n",
    "        \"distance_cm\",\n",
    "        \"step_label\",\n",
    "        \"source_label\"\n",
    "    )\n",
    ")\n",
    "\n",
    "display(final_df_renamed.limit(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2e8aff-8cca-41b0-ad3e-da5a76da83c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, from_unixtime\n",
    "\n",
    "# Add human-readable timestamp columns (epoch ms -> timestamp)\n",
    "final_df_readable = (\n",
    "    final_df\n",
    "    .withColumn(\"timestamp_ts\", to_timestamp(from_unixtime(col(\"timestamp\") / 1000)))\n",
    ")\n",
    "\n",
    "display(final_df_readable.select(\"timestamp\", \"timestamp_ts\", \"device_id\", \"sensor_type\", \"distance_cm\", \"step_label\").limit(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfa907bc-773c-47ce-b82f-29fdfc381137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "final_df = (\n",
    "    device_prepped.alias(\"d\")\n",
    "    .join(\n",
    "        steps_window.alias(\"s\"),\n",
    "        (col(\"d.device_id\") == col(\"s.device_id\")) &\n",
    "        (col(\"d.timestamp\").between(col(\"s.start_time\"), col(\"s.stop_time\"))),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"step_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), lit(\"step\")).otherwise(lit(\"no_step\"))\n",
    "    )\n",
    "    .select(\n",
    "        col(\"d.timestamp\").alias(\"timestamp\"),\n",
    "        col(\"d.device_id\").alias(\"device_id\"),\n",
    "        col(\"d.sensor_type\").alias(\"sensor_type\"),\n",
    "        col(\"d.distance_cm\").alias(\"distance_cm\"),\n",
    "        \"step_label\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86714a3a-a04b-4445-83c3-accaa5cad28a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join on device_id and timestamp window to label step/no_step.\n",
    "final_df = (\n",
    "    device_prepped.alias(\"d\")\n",
    "    .join(\n",
    "        steps_window.alias(\"s\"),\n",
    "        (col(\"d.device_id\") == col(\"s.device_id\")) &\n",
    "        (col(\"d.timestamp\").between(col(\"s.start_time\"), col(\"s.stop_time\"))),\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"step_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), lit(\"step\")).otherwise(lit(\"no_step\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"source_label\",\n",
    "        when(col(\"s.start_time\").isNotNull(), lit(\"step\")).otherwise(lit(\"device\"))\n",
    "    )\n",
    "    .select(\n",
    "        col(\"d.timestamp\").alias(\"timestamp\"),\n",
    "        col(\"d.device_id\").alias(\"device_id\"),\n",
    "        col(\"d.sensor_type\").alias(\"sensor_type\"),\n",
    "        col(\"d.distance_cm\").alias(\"distance_cm\"),\n",
    "        \"step_label\",\n",
    "        \"source_label\"\n",
    "    )\n",
    ")\n",
    "\n",
    "display(final_df.limit(20))\n",
    "final_df.groupBy(\"step_label\").count().show()\n",
    "final_df.groupBy(\"source_label\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171e6bce-8445-4116-a9c3-21946dd8c0d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df.createOrReplaceTempView(\"final_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31afb94e-46ef-4778-a326-1f53ecf434b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE labeled_step_test AS\n",
    "SELECT * FROM final_df;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2381bb6e-a61b-412d-9c6e-c6a42a0c09fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(*) AS row_count\n",
    "FROM labeled_step_test;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a3a337-9324-4f0f-8cd1-d82b8ebea15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT step_label, COUNT(*) AS cnt\n",
    "FROM labeled_step_test\n",
    "GROUP BY step_label;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0e8e9ac-502f-45a1-90db-d6d171247692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE step_label NOT IN ('step', 'no_step')\n",
    "   OR step_label IS NULL\n",
    "LIMIT 50;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c9b4054-6423-4cac-a560-227db25b9dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT source_label, COUNT(*) AS cnt\n",
    "FROM labeled_step_test\n",
    "GROUP BY source_label;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e23c5cc-b634-4792-8a7f-15d031ff8d13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM labeled_step_test\n",
    "WHERE source_label NOT IN ('device', 'step')\n",
    "   OR source_label IS NULL\n",
    "LIMIT 50;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4094f9be-f772-44ee-951f-36ef7d799c8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When you automate health-ish data pipelines, you’re responsible for protecting privacy and not exposing identifiers like device IDs more than necessary. You also need validation every run so bad labels or schema changes don’t quietly spread downstream. Since people tend to trust automated outputs, document what the labels really mean and where they can be wrong. Watch for bias from missing data or uneven participation, and avoid medical claims. This is activity labeling, not a diagnosis."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8377166329912174,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_4_stedi_etl_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
