{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a9aa544-5f0e-4ee2-a3da-f2bec79a3e8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "load_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "pipeline = joblib.load(os.path.join(load_dir, \"stedi_feature_pipeline.pkl\"))\n",
    "X_train_transformed = joblib.load(os.path.join(load_dir, \"X_train_transformed.pkl\"))\n",
    "X_test_transformed  = joblib.load(os.path.join(load_dir, \"X_test_transformed.pkl\"))\n",
    "y_train = joblib.load(os.path.join(load_dir, \"y_train.pkl\"))\n",
    "y_test  = joblib.load(os.path.join(load_dir, \"y_test.pkl\"))\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test  = to_float_matrix(X_test_transformed)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92a60725-6b48-4fa4-a07c-f31b726ef1ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the explainability results, num__distance_cm was by far the most influential feature, and several one-hot device_id features (such as spotter-14 and spotter-16) also ranked highly, suggesting the model may be relying on device-specific patterns in addition to motion-derived signals. A concerning behavior is that the model’s performance is dominated by the majority class: despite high overall accuracy, it predicts “step” for every sample, which the confusion matrix confirms. The biggest weakness, therefore, is the model’s complete failure to identify no_step, creating extreme false positives and making the model unsafe for distinguishing stepping from non-stepping periods without further refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f20a2071-860d-44e9-a249-79dc376de1dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Focused refinement grid for Logistic Regression (small + purposeful)\n",
    "params = {\n",
    "    \"C\": [0.003, 0.01, 0.03, 0.1, 0.3, 1.0],     # centered around the previous best C=0.01\n",
    "    \"class_weight\": [None, \"balanced\"],          # address severe class imbalance\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"max_iter\": [1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0987054d-44a3-4b5e-b9fa-752751521275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SHAP and global importance show the model relies most on num__distance_cm, with several device_id one-hot features also ranking highly. Because the confusion matrix shows the model predicts step for every sample, I’m running a small, focused grid around the previous best C=0.01 and adding class_weight='balanced' to reduce the impact of class imbalance and improve minority-class performance rather than chasing accuracy alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9378014b-63e5-45ce-ab6b-5d6bfecd57e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# focused refinement grid (from Step 3)\n",
    "params = {\n",
    "    \"C\": [0.003, 0.01, 0.03, 0.1, 0.3, 1.0],\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    params,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "new_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58ece650-d410-49e3-8cf6-08eea6735440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rebuild the Week 5 winner as your \"old\" baseline\n",
    "old_model = LogisticRegression(C=0.01, penalty=\"l2\", solver=\"lbfgs\", max_iter=1000)\n",
    "old_model.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(name, model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y, y_pred)\n",
    "    f1_macro = f1_score(y, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"accuracy={acc:.4f}  balanced_accuracy={bal_acc:.4f}  macro_f1={f1_macro:.4f}\")\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    # Confusion matrix heatmap (extra credit-friendly)\n",
    "    labels = [\"no_step\", \"step\"] if set(np.unique(y)).issubset({\"no_step\", \"step\"}) else None\n",
    "    cm = confusion_matrix(y, y_pred, labels=labels)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot(values_format=\"d\")\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC curve (extra credit-friendly, requires predict_proba)\n",
    "    if hasattr(model, \"predict_proba\") and labels is not None:\n",
    "        step_index = list(model.classes_).index(\"step\")\n",
    "        proba_step = model.predict_proba(X)[:, step_index]\n",
    "        y_bin = (y == \"step\").astype(int)\n",
    "        RocCurveDisplay.from_predictions(y_bin, proba_step)\n",
    "        plt.title(f\"ROC Curve: {name}\")\n",
    "        plt.show()\n",
    "\n",
    "evaluate(\"Old model (Week 5 baseline)\", old_model, X_test, y_test)\n",
    "evaluate(\"New tuned model (GridSearch best)\", new_model, X_test, y_test)\n",
    "\n",
    "print(\"\\nOld CV best score (Week 5): 0.9511214840660257\")\n",
    "print(\"New CV best score (this grid):\", grid.best_score_)\n",
    "print(\"New best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34b549ca-17e4-407d-9ce4-ebc043fa7f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Old model score: The Week 5 baseline Logistic Regression model had a best cross-validation accuracy of 0.9511. On the test set it achieved accuracy = 0.9511, balanced accuracy = 0.5000, and macro F1 = 0.4875, and the confusion matrix shows it predicts “step” for every example. New tuned model score: the refined GridSearch model achieved best CV accuracy = 0.9511 with params C = 0.003 (class_weight = None), and on the test set it produced the same results: accuracy = 0.9511, balanced accuracy = 0.5000, and macro F1 = 0.4875, again predicting “step” for every example. The new tuning did not improve meaningful performance, so I will not switch models because it does not fix the model’s failure to detect the no_step class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d728e73-d086-4fa5-9b12-9262e80339db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "\n",
    "def first_writable_dir(candidates):\n",
    "    for d in candidates:\n",
    "        try:\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "            test_path = os.path.join(d, \".write_test\")\n",
    "            with open(test_path, \"w\") as f:\n",
    "                f.write(\"ok\")\n",
    "            os.remove(test_path)\n",
    "            return d\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise RuntimeError(\"No writable directory found in candidates.\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "candidates = [\n",
    "    os.path.join(cwd, \"exports\", \"model\"),   # best if you're in a Repo\n",
    "    os.path.join(cwd, \"model\"),              # also good in a Repo\n",
    "    \"/tmp/stedi_exports/model\",              # driver-local fallback\n",
    "    \"/local_disk0/tmp/stedi_exports/model\",  # another common driver-local fallback\n",
    "]\n",
    "\n",
    "save_dir = first_writable_dir(candidates)\n",
    "save_path = os.path.join(save_dir, \"stedi_best_model.pkl\")\n",
    "\n",
    "joblib.dump(old_model, save_path)\n",
    "\n",
    "print(\"Saved model to:\", save_path)\n",
    "print(\"File size (bytes):\", os.path.getsize(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a7f60b8-ea52-4dca-bc57-688c64e04d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "reloaded = joblib.load(\"/Workspace/Users/tcm082@ensign.edu/csai382_lab_2_4_-tmuhlestein-/notebooks/exports/model/stedi_best_model.pkl\")\n",
    "\n",
    "print(type(reloaded))\n",
    "print(\"Sample preds:\", reloaded.predict(X_test[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9369ceb-3128-4195-9a94-931aff81b777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = reloaded.predict(X_test)\n",
    "\n",
    "print(\"Unique predictions + counts:\", np.unique(y_pred, return_counts=True))\n",
    "\n",
    "# If your labels are strings like 'no_step'/'step'\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"no_step\", \"step\"])\n",
    "print(\"Confusion matrix [[no_step, step] rows x [no_step, step] cols]:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f656446-02af-43e3-b071-608bc3a4ec69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I saved the final selected model to a writable workspace path: /Workspace/Users/tcm082@ensign.edu/csai382_lab_2_4_-tmuhlestein-/notebooks/exports/model/stedi_best_model.pkl. This ensures the notebook contains an exported model artifact even though DBFS/FileStore and the earlier shared pipeline directories were not writable in this environment. I also verified the file by reloading it and confirming it produces predictions successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f566555e-1a5d-4fdd-84ef-9f9a507e5172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Refinement Summary\n",
    "I performed a second, focused hyperparameter search on Logistic Regression centered around the previous best C value and tested class weighting to address the severe class imbalance revealed by the confusion matrix and explainability results. The refined GridSearchCV produced the same best CV accuracy as the original model and selected C=0.003 with class_weight=None, which did not change the model’s behavior on the minority class. On the test set, the refined model still predicted “step” for essentially all samples, so I did not update the final model. This decision is responsible because it avoids claiming improvement when the refinement did not address the model’s most important weakness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94c997f3-20c7-4dfd-9465-8247edf6d53f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Reflection\n",
    "Careless hyperparameter tuning can create unfair or unsafe models when it optimizes a metric like accuracy that can look strong while the model ignores a minority class. That’s why it’s important to examine confusion matrices, per-class metrics, and explainability instead of trusting a single score. SHAP and feature importance help reveal whether the model is learning real movement patterns or relying on shortcuts that may fail on new users or devices. Gospel principles of integrity and stewardship guide me to report results honestly and choose decisions that reflect the model’s actual behavior, “by their fruits ye shall know them.”"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.6_hyperparameter_tuning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
