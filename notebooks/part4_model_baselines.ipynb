{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76ee2dd-30df-45ed-b3e7-29cdde76da72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "etl_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"etl_pipeline dir exists?\", os.path.exists(etl_dir))\n",
    "if os.path.exists(etl_dir):\n",
    "    print(\"Files in etl_pipeline:\", os.listdir(etl_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32901152-ba84-4ac5-a4ab-c1d53b932c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json, os, glob\n",
    "\n",
    "keywords = [\n",
    "    \"Pipeline(\", \"ColumnTransformer\", \"joblib.dump\", \"X_train_transformed\",\n",
    "    \"fit_transform\", \"train_test_split\", \"stedi_feature_pipeline\"\n",
    "]\n",
    "\n",
    "for path in sorted(glob.glob(\"*.ipynb\")):\n",
    "    try:\n",
    "        nb = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "        text = \"\\n\".join(\n",
    "            \"\".join(cell.get(\"source\", \"\")) for cell in nb.get(\"cells\", [])\n",
    "            if cell.get(\"cell_type\") in (\"code\", \"markdown\")\n",
    "        )\n",
    "        hits = [k for k in keywords if k in text]\n",
    "        if hits:\n",
    "            print(path, \"->\", hits)\n",
    "    except Exception as e:\n",
    "        print(path, \"-> couldn't read:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "522035bb-4155-4d8a-ac56-fdb32cd96fb9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Saved Pipeline and Processed Data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.table(\"silver.labeled_step_test\").toPandas()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d2a6a66-9fe0-405b-8091-49ec88b38a22",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Confirm columns"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176689d8-276f-48ab-81a5-e34164547991",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define features/label and do the train/test split"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols_numeric = [\"distance_cm\"]\n",
    "feature_cols_categorical = [\"sensor_type\", \"device_id\"]\n",
    "label_col = \"step_label\"\n",
    "\n",
    "X = df[feature_cols_numeric + feature_cols_categorical]\n",
    "y = df[label_col]\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train_raw.shape, \"Test:\", X_test_raw.shape)\n",
    "print(\"Train label %:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test label %:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4e9697-df8d-46a8-9cc3-30c64d05780f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build preprocessing pipeline"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, feature_cols_numeric),\n",
    "        (\"cat\", categorical_transformer, feature_cols_categorical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"preprocess\", preprocessor)])\n",
    "\n",
    "pipeline.fit(X_train_raw)\n",
    "\n",
    "X_train = pipeline.transform(X_train_raw)\n",
    "X_test  = pipeline.transform(X_test_raw)\n",
    "\n",
    "print(\"Transformed shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"Type:\", type(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54e75861-172b-4f0f-a4e2-78a4b3bd17c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Logistic regression"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg_score = log_reg.score(X_test, y_test)\n",
    "log_reg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "996155dd-ce6e-4713-909c-4aa5f79a218e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Random forest"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc755f5e-d943-4889-a2e5-933992ab1d12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Comparison dictionary"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Logistic Regression baseline\": log_reg_score,\n",
    "    \"Random Forest baseline\": rf_score\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5606d01d-7fbc-46a2-8425-998cec56b7f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Markdown\n",
    "Logistic Regression performed slightly better than Random Forest (0.9511 vs 0.9508 accuracy), though the difference is tiny. For noisy sensor data, Logistic Regression can be more stable because it’s simpler and less likely to overfit, while Random Forest can chase noise even if it sometimes captures complex patterns better. I’m wondering why the scores are so close. Does the heavy class imbalance (about 95% “step”) make accuracy less meaningful, and how do the models compare specifically on the minority “no_step” cases? I also wonder whether tuning Random Forest parameters (like depth or number of trees) would change the result. Testing matters before real use because wrong predictions could affect people wearing the device (missed steps or false alerts) and anyone relying on the data (researchers, clinicians, or decision-makers). Fairness matters because models can silently perform worse on minority cases or certain devices/sensor types, and discipleship also requires applying principles consistently and justly rather than unevenly."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "part4_model_baselines",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
