{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8961fc2-ab26-46d3-a2c3-113d9328d433",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load saved pipeline, best model, and transformed data"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Your CWD is .../notebooks, so project root is one level up\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "load_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "pipeline = joblib.load(os.path.join(load_dir, \"stedi_feature_pipeline.pkl\"))\n",
    "model = joblib.load(os.path.join(load_dir, \"stedi_best_model.pkl\"))\n",
    "\n",
    "X_train_transformed = joblib.load(os.path.join(load_dir, \"X_train_transformed.pkl\"))\n",
    "X_test_transformed  = joblib.load(os.path.join(load_dir, \"X_test_transformed.pkl\"))\n",
    "y_train = joblib.load(os.path.join(load_dir, \"y_train.pkl\"))\n",
    "y_test  = joblib.load(os.path.join(load_dir, \"y_test.pkl\"))\n",
    "\n",
    "def to_float_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.ndim == 0:\n",
    "        arr = arr.item()\n",
    "        if issparse(arr):\n",
    "            arr = arr.toarray()\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    elif arr.dtype == object:\n",
    "        arr = np.array([\n",
    "            x.toarray() if issparse(x) else np.array(x, dtype=float)\n",
    "            for x in arr\n",
    "        ])\n",
    "        arr = np.vstack(arr)\n",
    "    elif issparse(arr):\n",
    "        arr = arr.toarray()\n",
    "    else:\n",
    "        arr = np.array(arr, dtype=float)\n",
    "    return arr\n",
    "\n",
    "X_train = to_float_matrix(X_train_transformed)\n",
    "X_test  = to_float_matrix(X_test_transformed)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test  = np.ravel(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66040821-aef9-4adc-abb8-9fd28c75c8cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get feature names"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    feature_names = pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    feature_names = np.array([f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "\n",
    "len(feature_names), feature_names[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270fda3f-175c-4207-a6fe-b3fc71d52739",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Global feature importance (top 10)"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "    importance_label = \"Feature importance (Random Forest)\"\n",
    "elif hasattr(model, \"coef_\"):\n",
    "    importances = np.abs(model.coef_[0])\n",
    "    importance_label = \"Absolute coefficient magnitude (Logistic Regression)\"\n",
    "else:\n",
    "    raise ValueError(\"Model has neither feature_importances_ nor coef_.\")\n",
    "\n",
    "importance_order = np.argsort(importances)[::-1]\n",
    "\n",
    "for idx in importance_order[:10]:\n",
    "    print(feature_names[idx], \":\", importances[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01413f81-e2b6-48a2-afe8-3f358febf9c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Does this importance pattern make sense?\n",
    "The importance pattern mostly makes sense in one respect: distance_cm being the top numeric feature is reasonable, since steps should correlate with changes in movement/distance. What’s more surprising is that many of the next most “important” features are device_id one-hot categories (spotter-14, spotter-16, spotter-1, etc.). That suggests the model may be learning device-specific quirks (sensor calibration, placement, user behavior, collection conditions) instead of purely learning step vs. no_step behavior.\n",
    "\n",
    "I wouldn’t fully trust predictions based on this pattern without more checks, because reliance on device_id can act like a shortcut and can reduce generalization to new devices or users. It also raises a fairness concern: if some devices are associated with different environments or populations, the model could perform well for devices it has seen and poorly for others, while overall accuracy still looks high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e21e410b-39ab-45c7-9ea5-ff7b1c9312c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73101d85-3742-44b0-86fd-8925e25a538b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Plot global feature importance"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_n = 10\n",
    "top_idx = importance_order[:top_n]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh([feature_names[i] for i in top_idx], importances[top_idx])\n",
    "plt.xlabel(importance_label)\n",
    "plt.title(\"Top Global Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d50bfa7b-0cd8-4fe3-a5a1-a10f7f641870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install numpy==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fc2d39b-8688-4285-b1a6-361389b5914d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f19edb-8a6e-4d75-bb15-b10552b7823f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SHAP setup and SHAP values"
    }
   },
   "outputs": [],
   "source": [
    "# If import shap fails, run these two lines in a separate cell:\n",
    "%pip install shap\n",
    "# dbutils.library.restartPython()\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Tree models vs linear models need different explainers\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "else:\n",
    "    explainer = shap.LinearExplainer(model, X_train)\n",
    "    shap_values = explainer.shap_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ca0d24-6f5f-41b9-8ae7-e013274d0960",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SHAP summary plot (global view)"
    }
   },
   "outputs": [],
   "source": [
    "# For binary classification, shap_values usually gives per-class explanations for tree models,\n",
    "# and a 2-D array for linear models.\n",
    "if isinstance(shap_values, list):\n",
    "    shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, rng=42)\n",
    "else:\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=feature_names, rng=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "385b8855-66f8-4923-aa88-503de24a067c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#SHAP summary plot\n",
    "The SHAP summary plot matches the global importance results: num__distance_cm is clearly the strongest driver of predictions, and many device_id one-hot features also have noticeable influence. In general, larger values of distance_cm tend to push the model more strongly in one direction, which fits the idea that steps involve larger movement changes.\n",
    "\n",
    "It’s concerning that device_id features appear so prominent, because that suggests the model may be learning device-specific patterns rather than a general “step vs. no_step” concept. This also fits what we observed earlier: the model behaves like it defaults to predicting step, so these SHAP effects may be explaining a majority-class shortcut rather than balanced reasoning across both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33df0a46-4a36-4291-bcc3-dec6f0646b04",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SHAP force plot (single prediction)"
    }
   },
   "outputs": [],
   "source": [
    "i = 0  # pick any row index you want\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value[1],\n",
    "        shap_values[1][i],\n",
    "        X_test[i],\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "else:\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[i],\n",
    "        X_test[i],\n",
    "        feature_names=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa90804b-9bdb-44a5-93b5-5a8faa177f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Reflection\n",
    "Globally, the model is most influenced by num_distance_cm, followed by several device_id indicators and sensor_type. Distance makes intuitive sense because steps should correlate with movement, but the heavy reliance on device identity suggests the model may be learning device-specific quirks rather than purely learning step behavior.\n",
    "\n",
    "Locally, the SHAP force plot shows a small number of features doing most of the work for a single prediction, with distance and device-related indicators pushing the output in the same direction as the overall model. That makes the decision explainable, but it also reinforces the concern that the model may be defaulting to majority-class behavior rather than carefully separating step from no_step.\n",
    "\n",
    "A human would expect motion features to matter most, so the distance result matches intuition, but the prominence of device_id is a warning sign for generalization and fairness. For the dashboard, I plan to include the global feature importance bar chart, the SHAP summary plot, and one SHAP force plot example to show both overall behavior and a single-row explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7584af69-2d89-4f8e-b0ca-067fed9f3a87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, joblib\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "load_dir = os.path.join(project_root, \"etl_pipeline\")\n",
    "\n",
    "print(\"load_dir:\", load_dir)\n",
    "print(\"etl_pipeline contents:\", os.listdir(load_dir))\n",
    "\n",
    "model_path = os.path.join(load_dir, \"stedi_best_model.pkl\")\n",
    "print(\"model_path:\", model_path, \"exists:\", os.path.exists(model_path))\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "type(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d446e32-75aa-47fb-988e-b6b96c1cda60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "part5_feature_importance_shap.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
